{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "Y = data['Y']\n",
    "data = data.drop(['Y'], axis = 1)\n",
    "\n",
    "\n",
    "data_scaled = pd.read_csv('../data/data_scaled.csv')\n",
    "Y_scaled = data_scaled['Y']\n",
    "data_scaled = data_scaled.drop(['Unnamed: 0', 'Y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.2)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data_scaled, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 1.0\n",
      "performance over the test set: 0.18691588785046728\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       992\n",
      "           1       0.43      0.12      0.19        84\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.68      0.55      0.57      1076\n",
      "weighted avg       0.89      0.92      0.90      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not Scaled Dataset\n",
    "# STEP 1 - First XGB - Highly Overfitted\n",
    "# Fiz Learning Rate and n_estimators\n",
    "\n",
    "xgb1_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=5,\n",
    "                                        min_child_weight=1,                         \n",
    "                                        gamma=0,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb1_model.fit(X_train,y_train)\n",
    "y_predicted = xgb1_model.predict(X_test)\n",
    "y_predicted_train = xgb1_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'min_child_weight': 4}, 0.16407333382683148)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2 - Tuning max_depth and min_child_weight\n",
    "\n",
    "param_test2 = {\n",
    "    'max_depth':range(1,7,1),\n",
    "    'min_child_weight':range(0,7,1)\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=4,\n",
    "                                                  gamma=0,  \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic',\n",
    "                                                  scale_pos_weight=1, \n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test2, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.7890625\n",
      "performance over the test set: 0.15094339622641512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       993\n",
      "           1       0.35      0.10      0.15        83\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.64      0.54      0.55      1076\n",
      "weighted avg       0.88      0.92      0.89      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Testing New Parameters\n",
    "\n",
    "xgb2_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb2_model.fit(X_train,y_train)\n",
    "y_predicted = xgb2_model.predict(X_test)\n",
    "y_predicted_train = xgb2_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'gamma': 0.0}, 0.18547316732055688)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3 - Tuning Gamma \n",
    "\n",
    "param_test3 = { \n",
    "    'gamma':[i/10.0 for i in range(0,5)] \n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic',\n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test3, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.7953216374269005\n",
      "performance over the test set: 0.18018018018018017\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       992\n",
      "           1       0.37      0.12      0.18        84\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.65      0.55      0.57      1076\n",
      "weighted avg       0.89      0.92      0.89      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing New Parameters\n",
    "\n",
    "xgb3_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective = 'binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb3_model.fit(X_train,y_train)\n",
    "y_predicted = xgb3_model.predict(X_test)\n",
    "y_predicted_train = xgb3_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.8, 'subsample': 1.0}, 0.18547316732055688)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 4 - Tuning colsample_bytree and subsaample\n",
    "\n",
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(7,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(7,11)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test4, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch4.fit(X_train, y_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.7890625\n",
      "performance over the test set: 0.15094339622641512\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       993\n",
      "           1       0.35      0.10      0.15        83\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.64      0.54      0.55      1076\n",
      "weighted avg       0.88      0.92      0.89      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing New Parameters\n",
    "\n",
    "xgb4_model = XGBClassifier( learning_rate=0.1, \n",
    "                                        n_estimators=1200,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        subsample=1,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb4_model.fit(X_train,y_train)\n",
    "y_predicted = xgb4_model.predict(X_test)\n",
    "y_predicted_train = xgb4_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 2}, 0.1663915032336085)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 - Tuning Regularization Parameters\n",
    "# Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[1e-2, 0.1, 0.5, 1, 2, 10]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  reg_lambda = 2,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 3}, 0.17262618083670717)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closer Look - Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[2, 3, 4, 5]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  reg_lambda = 3,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_lambda': 3}, 0.17262618083670717)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even Closer Look - Lambda L2 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_lambda':[2.6, 2.8, 3, 3.2, 3.4]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  reg_lambda = 3,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'reg_alpha': 1e-05}, 0.17262618083670717)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alpha L1 Regularization\n",
    "\n",
    "param_test5 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1200, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  reg_lambda = 3,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test5, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.07}, 0.16661248265677714)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 6 - Reducing Learning Rate and Adding More Trees\n",
    "\n",
    "param_test6 = {\n",
    "    'learning_rate':[i/100.0 for i in range(5,20,2)]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=3000, \n",
    "                                                  max_depth = 3,\n",
    "                                                  min_child_weight = 5,\n",
    "                                                  gamma=0, \n",
    "                                                  subsample=1, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  reg_alpha=0,\n",
    "                                                  reg_lambda=3,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=42), \n",
    "                        param_grid = param_test6, \n",
    "                        scoring='f1',\n",
    "                        n_jobs=4,\n",
    "                        iid=False, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch6.fit(X_train, y_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.9236111111111112\n",
      "performance over the test set: 0.14953271028037382\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       993\n",
      "           1       0.33      0.10      0.15        83\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.63      0.54      0.55      1076\n",
      "weighted avg       0.88      0.92      0.89      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Evaluation\n",
    "\n",
    "\n",
    "xgb6_model = XGBClassifier(learning_rate=0.07, \n",
    "                                        n_estimators=3000,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        subsample=1,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        reg_alpha=0,\n",
    "                                        reg_lambda=3,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb6_model.fit(X_train,y_train)\n",
    "y_predicted = xgb6_model.predict(X_test)\n",
    "y_predicted_train = xgb6_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance over the training set: 0.7914230019493177\n",
      "performance over the test set: 0.15686274509803924\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       993\n",
      "           1       0.42      0.10      0.16        83\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.68      0.54      0.56      1076\n",
      "weighted avg       0.89      0.92      0.90      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Evaluation\n",
    "\n",
    "\n",
    "xgb6_model = XGBClassifier(learning_rate=0.07, \n",
    "                                        n_estimators=2000,\n",
    "                                        max_depth=3,\n",
    "                                        min_child_weight=5,                         \n",
    "                                        gamma=0,\n",
    "                                        subsample=1,\n",
    "                                        colsample_bytree=0.8,\n",
    "                                        reg_alpha=0,\n",
    "                                        reg_lambda=3,\n",
    "                                        objective ='binary:logistic',\n",
    "                                        scale_pos_weight = 1,\n",
    "                                        seed=42)\n",
    "\n",
    "\n",
    "xgb6_model.fit(X_train,y_train)\n",
    "y_predicted = xgb6_model.predict(X_test)\n",
    "y_predicted_train = xgb6_model.predict(X_train)\n",
    "\n",
    "\n",
    "print('performance over the training set: ' + str(f1_score(y_train, y_predicted_train)))\n",
    "print('performance over the test set: ' + str(f1_score(y_test, y_predicted)) + '\\n')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
